## Linear Model

### Columns selection

The whole dataset has 16 columns and 731 rows. The main prediction of this model is predict the total number of people who rental bikes which means the y column is the tot column. The column which may not have connection to the number of people who rent bike is instant. The column of mnth, holiday, weekday, workingday have high connection which means we can only choose one of the column as data. The weather will highly affect the number of people who willing to go biking, which means all of the weather column need to be selected. 

Random choose 100 data from whole data set as test data and the rest as training data.

### Data normalize

All of the data from different column have high difference which means normalize the dataset will help the linear regression better fitting the dataset. We choose to use the mean max normalize to normalize the dataset and split it into training and testing set.

### Create Model

```R
linearMod <- lm(train_y[,1] ~ train_x[,1] + train_x[,2] + train_x[,3] + train_x[,4] + train_x[,5] + train_x[,6] + train_x[,7] + train_x[,8] + train_x[,9])
```

The linearModel has weight 1812.705 1536.296 2044.861 -463.4453 203.7525 -1161.559 1522.226 2973.805 -1093.731 -1261.305



The regression line is 

tot = 1812.705 + x1 * 1536.296 + x2 * 2044.861 +  x3 * (-463.4453) + x4 * 203.7525 + x5 * (-1161.559) + x6 *  1522.226  + x7 * 2973.805 + x8* (-1093.731) + x9 * (-1261.305)



### Check error

We choose to use mean square error and build in summary method to measure the error of this linear model.

```
Call:
lm(formula = train_y[, 1] ~ train_x[, 1] + train_x[, 2] + train_x[, 
    3] + train_x[, 4] + train_x[, 5] + train_x[, 6] + train_x[, 
    7] + train_x[, 8] + train_x[, 9])

Residuals:
    Min      1Q  Median      3Q     Max 
-4301.0  -464.1    68.9   511.2  3197.3 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)   1812.71     245.13   7.395 4.60e-13 ***
train_x[, 1]  1536.30     185.69   8.274 7.94e-16 ***
train_x[, 2]  2044.86      70.91  28.836  < 2e-16 ***
train_x[, 3]  -463.45     212.17  -2.184 0.029310 *  
train_x[, 4]   203.75      75.52   2.698 0.007169 ** 
train_x[, 5] -1161.56     167.57  -6.932 1.04e-11 ***
train_x[, 6]  1522.23    1166.50   1.305 0.192391    
train_x[, 7]  2973.81    1256.29   2.367 0.018232 *  
train_x[, 8] -1093.73     326.51  -3.350 0.000858 ***
train_x[, 9] -1261.30     235.53  -5.355 1.21e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 877.7 on 621 degrees of freedom
Multiple R-squared:  0.8005,    Adjusted R-squared:  0.7976 
F-statistic: 276.8 on 9 and 621 DF,  p-value: < 2.2e-16
```

Overall the mean square error of this linear model is 0.02298344

### Whole code

check appendix.

![](C:\Users\Cloud\OneDrive\Class\2019\fall\ECS 132\Final Project\ECS-132-Final-Project\ProblemB\plots\Rplot.png)

![0](C:\Users\Cloud\OneDrive\Class\2019\fall\ECS 132\Final Project\ECS-132-Final-Project\ProblemB\plots\Rplot01.png)

![](C:\Users\Cloud\OneDrive\Class\2019\fall\ECS 132\Final Project\ECS-132-Final-Project\ProblemB\plots\Rplot02.png)